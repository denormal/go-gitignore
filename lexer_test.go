// Copyright 2016 Denormal Limited
// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package gitignore_test

import (
	"fmt"
	"strings"
	"testing"

	"github.com/ianlewis/go-gitignore"
)

// TestLexerNewLne tests the behavour of the gitignore.Lexer when the input
// data explicitly uses "\n" as the line separator
func TestLexerNewLine(t *testing.T) {
	// split the test content into lines
	//		- ensure we handle "\n" and "\r" correctly
	//		- since this test file is written on a system that uses "\n"
	//		  to designate end of line, this should be unnecessary, but it's
	//		  possible for the file line endings to be converted outside of
	//		  this repository, so we are thorough here to ensure the test
	//		  works as expected everywhere
	_content := strings.Split(_GITIGNORE, "\n")
	for _i := 0; _i < len(_content); _i++ {
		_content[_i] = strings.TrimSuffix(_content[_i], "\r")
	}

	// perform the Lexer test with input explicitly separated by "\n"
	lexer(t, _content, "\n", _GITTOKENS, nil)
} // TestLexerNewLine()

// TestLexerCarriageReturn tests the behavour of the gitignore.Lexer when the
// input data explicitly uses "\r\n" as the line separator
func TestLexerCarriageReturn(t *testing.T) {
	// split the test content into lines
	//		- see above
	_content := strings.Split(_GITIGNORE, "\n")
	for _i := 0; _i < len(_content); _i++ {
		_content[_i] = strings.TrimSuffix(_content[_i], "\r")
	}

	// perform the Lexer test with input explicitly separated by "\r\n"
	lexer(t, _content, "\r\n", _GITTOKENS, nil)
} // TestLexerCarriageReturn()

func TestLexerInvalidNewLine(t *testing.T) {
	// perform the Lexer test with invalid input separated by "\n"
	//		- the source content is manually constructed with "\n" as EOL
	_content := strings.Split(_GITINVALID, "\n")
	lexer(t, _content, "\n", _TOKENSINVALID, gitignore.CarriageReturnError)
} // TestLexerInvalidNewLine()

func TestLexerInvalidCarriageReturn(t *testing.T) {
	// perform the Lexer test with invalid input separated by "\n"
	//		- the source content is manually constructed with "\n" as EOL
	_content := strings.Split(_GITINVALID, "\n")
	lexer(t, _content, "\r\n", _TOKENSINVALID, gitignore.CarriageReturnError)
} // TestLexerInvalidCarriageReturn()

func lexer(t *testing.T, lines []string, eol string, tokens []token, e error) {
	// create a temporary .gitignore
	_buffer, _err := buffer(strings.Join(lines, eol))
	if _err != nil {
		t.Fatalf("unable to create temporary .gitignore: %s", _err.Error())
	}

	// ensure we have a non-nil Lexer instance
	_lexer := gitignore.NewLexer(_buffer)
	if _lexer == nil {
		t.Error("expected non-nil Lexer instance; nil found")
	}

	// ensure the stream of tokens is as we expect
	for _, _expected := range tokens {
		_position := _lexer.Position()

		// ensure the string form of the Lexer reports the correct position
		_string := fmt.Sprintf("%d:%d", _position.Line, _position.Column)
		if _lexer.String() != _string {
			t.Errorf(
				"lexer string mismatch; expected %q, got %q",
				_string, _position.String(),
			)
		}

		// extract the next token from the lexer
		_got, _err := _lexer.Next()

		// ensure we did not receive an error and the token is as expected
		if _err != nil {
			// if we expect an error during processing, check to see if
			// the received error is as expected
			//			if !_err.Is(e) {
			if _err.Underlying() != e {
				t.Fatalf(
					"unable to retrieve expected token; %s at %s",
					_err.Error(), pos(_err.Position()),
				)
			}
		}

		// did we receive a token?
		if _got == nil {
			t.Fatalf("expected token at %s; none found", _lexer)
		}

		if _got.Type != _expected.Type {
			t.Fatalf(
				"token type mismatch; expected type %d, got %d [%s]",
				_expected.Type, _got.Type, _got,
			)
		}

		if _got.Name() != _expected.Name {
			t.Fatalf(
				"token name mismatch; expected name %q, got %q [%s]",
				_expected.Name, _got.Name(), _got,
			)
		}

		// ensure the extracted token string matches expectation
		//		- we handle EOL separately, since it can change based
		//		  on the end of line sequence of the input file
		_same := _got.Token() == _expected.Token
		if _got.Type == gitignore.EOL {
			_same = _got.Token() == eol
		}
		if !_same {
			t.Fatalf(
				"token value mismatch; expected name %q, got %q [%s]",
				_expected.Token, _got.Token(), _got,
			)
		}

		// ensure the token position matches the original lexer position
		if !coincident(_got.Position, _position) {
			t.Fatalf(
				"token position mismatch for %s; expected %s, got %s",
				_got, pos(_position), pos(_got.Position),
			)
		}

		// ensure the token position matches the expected position
		//		- since we will be testing with different line endings, we
		//		  have to choose the correct offset
		_ignorePosition := gitignore.Position{
			File:   "",
			Line:   _expected.Line,
			Column: _expected.Column,
			Offset: _expected.NewLine,
		}
		if eol == "\r\n" {
			_ignorePosition.Offset = _expected.CarriageReturn
		}
		if !coincident(_got.Position, _ignorePosition) {
			t.Log(pos(_got.Position) + "\t" + _got.String())
			t.Fatalf(
				"token position mismatch; expected %s, got %s",
				pos(_ignorePosition), pos(_got.Position),
			)
		}
	}

	// ensure there are no more tokens
	_next, _err := _lexer.Next()
	if _err != nil {
		t.Errorf("unexpected error on end of token test: %s", _err.Error())
	} else if _next == nil {
		t.Errorf("unexpected nil token at end of test")
	} else if _next.Type != gitignore.EOF {
		t.Errorf(
			"token type mismatch; expected type %d, got %d [%s]",
			gitignore.EOF, _next.Type, _next,
		)
	}
} // TestLexer()
